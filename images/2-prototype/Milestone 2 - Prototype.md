# Milestone 2 - Prototype

Team UFT - Junha Hyung, Hyunji Lee, Jeongeon Park

2021 Spring, CS492(E) Human-AI Interaction, KAIST

---

### Project Summary
When students are reviewing the lecture after class, it is difficult for them to review the lecture solely with their notes, as they have unorganized and incomplete notes and a vast amount of recordings. 

To reorganize the lecture recording and the written notes to review past lectures, we present **DrNotes**, a summarization-based note recommendation system that helps users to save notes in a more complete form. 

The recording-to-summary feature we provide with different recommendation levels, and the drag-to-summarize that enables users' own fill in of their initial notes helps users to remember and recognize the important pars of the lecture longer.


### Instruction

#### Interface
![](https://github.com/amy-hyunji/doctor-notes/blob/main/images/doctor-notes-overall-image.png)

* Intro Page (Min/max length of the summary)
* Transcribed Lecture Recording Panel
* Summarization Panel
* My Notes Panel (Threshold Bar)
* Audio File Player
* Export Button

#### (Recommended) Take notes with automatic time detection note-taking service
![](https://github.com/amy-hyunji/doctor-notes/blob/main/images/doctor-notes-note-taking.png)

Image link: https://github.com/amy-hyunji/doctor-notes/blob/main/images/doctor-notes-note-taking.png

Enter the YouTube URL of the video you want to take note of. Play the video and write the notes on the bottom. The notes are taken in the form of bullet points, which is auto generated by pressing the enter key. When you press the enter key, the timestamp of when the user began writing is being recorded and added at the front of each bullet point. When you are done, click the `export` button to save your note in **.txt** format. 

> This is to simulate the lecture environment later in the user testing.
> Due to our API restrict, we recommend you to use a video shorter than 5 minutes.

#### Drop the lecture recording and the typed notes to the Intro Page
Upload the lecture recording and the typed notes. The format should be **.wav** and **.txt** respectively. In case your video is not in **.wav** format, visit https://convertio.co/kr/ for conversion. We **highly** recommend you to get the typed notes from our note-taking web, https://drnotes-notetaking.web.app/.

![](https://github.com/amy-hyunji/doctor-notes/blob/main/images/first-page.png)

Image path: https://github.com/amy-hyunji/doctor-notes/blob/main/images/first-page.png

#### Write the range of summarization similar to your notes
To get the suggested notes in a similar format as your notes, estimate the range of your minimum and the maximum length of your note and insert the two. The unit of length measurement is in a token but you can roughly get the same result by counting the number of words. 

#### Comprehend the transcribed lecture recording
You will be able to get the transcribed lecture recording which is the result of the speech-to-text model. Since there may be some wrong information, you can revise the script by checking the audio from the audio file player. 

#### Explore lecture recording summary with different threshold
By choosing the threshold, you can change the number of recommendations you get. Threshold 0 means choosing all and 1 means no recommendation is needed. This will help you understand the important notes for the lecture.

#### Fill your notes in with summary or the system suggestion
You can only leave the notes that you think are important from the suggestions as to the final notes by dragging the note from the second to the third column. Before adding to your notes, you can edit them in case you think some parts of summarization are wrong or not informative enough. You can add more notes if necessary by clicking the `edit` button on top of the third column. Also, if you want a summarization of a specific part, you can create a new note by dragging the text in the `recording` column. When you drag the text, you will be able to see the `Summarize?` button, and to summarize, click the button. The result will be shown in the second column after clearing the previous boxes inside the second column. You can add the summarized result to the user note by clicking the `Add this summary?` button on the right. When you want to go back to previous results, which had summarized results in the second column, press the `Ignore this summary and go back` button on the bottom.

#### Change the UI form
By clicking the buttons on top, which are `Recording`, `Summarization`, and `My Notes`, you can choose which columns you want to remove. If you click the button, the corresponding column will hide. 

#### Export the notes in PDF
Click the `Export` button to save your notes!




### Prototype
#### Prototype URL: https://drnotes-492e.web.app/

#### Additional Note-taking Prototype URL: https://drnotes-notetaking.web.app/
* The additional prototype is a tool to collect lecture notes prior to the review stage that **DrNotes** supports, so that we can get a lecture note with timestamp information.
* The note-taking prototype looks like the following: [Placeholder for image]

> *For both prototype, running in Safari is recommended.*

#### How to connect our service?
* 1. get the credential by accessing https://52.156.155.214:8887
* 2. Go through the protection wall 
* 3. Connect to https://drnotes-notetaking.web.app/
* 4. You can use our service now! 


#### Git Repository URL: https://github.com/amy-hyunji/doctor-notes

#### Libraries and Frameworks 
* Front-end: ReactJS, Semantic UI, Material-UI, react-audio-player ([link](https://www.npmjs.com/package/react-audio-player))
* Server: Flask
* Model: Python, Pytorch, huggingface, GoogleAPI
* **IMPORTANT**: Since we are paying for the speeech-to-text server, we hope the input audio to be short :)

### Individual Reflections

#### Junha Hyung
* Which part of the system did you directly contribute to?
    * I mostly worked on the backend and connected the speech to text googleAPI model.
* What were some of the difficulties you faced?
    * I first tried to train or use pre-trained speech to text model but current available models were all too big or it didn't work well. Main problem was that it didn't output the text in the sentence form but indicated them in character level which doesn't have any period or discrimination between lower or upper characters. I thought this will highly degrade the performance of summarization so I changed to googleAPI model which converted the indicated words into sentence format. Though there are still minor errors, we thought it shows sufficient performance.
    * There were lots of troubles on connection between user side and server side mostly because all three were new at the server side. However, we could solve the issues!
* List one useful skill you learned while working on the high-fi prototype.
    * I haven't worked with flask and googleAPI before so I learned a lot about how to build the backend server and connect it to the front-end side. There were diverse problems such as transfer format, credentials, and more. 

#### Hyunji Lee
* Which part of the system did you directly contribute to?
    * I worked on summarization and keyword scoring model and connected them on backend.
* What were some of the difficulties you faced?
    * There weren't any dataset in the domain we want which is note taken by people. So we had to find the model or finetune the model on dataset with similar domain. For summarization, I chose the model that was trained on news dataset and by sudo-dataset, I could see sufficient performance. For scoring, I first tried to finetune the model on masked language model, Bert, with PAWS dattaset and get the score from 0-1. However, using the whole range from 0 to 1 seemed too much. Therefore, I changed to the generative language model, T5, with three classes using S-NLI dataset. The three labels each indicate the Low, Med, High threshold of our recommendation. By using the model that was previously trained with NLI and had higher score, we believe the scoring is became more reliable. By training on the dataset, we could get the similarity between the two sentence rather than classifying them. Also, I had to reduce the inference time since it's real time and there are many pipeline in our process. 
    * There were lots of works to be done together especially when connecting the back and the front. It was difficult to communicate without meeting each other.
* List one useful skill you learned while working on the high-fi prototype.
    * I learned ways to reduce the inference time and how to efficiently load and organize the model to take care of the possible errors. Also, by solving the connection issues between the back and the front, I could learn about how they connect and some issues related to it.

#### Jeongeon Park
* Which part of the system did you directly contribute to?
    * I built the entire front-end side of the prototype, from building the overall structure to the three panels, and the features. I also discussed to connect the front with the server by various api calls.
* What were some of the difficulties you faced?
    * The most difficult part about the implementation was the CORS issue and the mixed content issue (sending a request as http:// from https://). As I usually use Firebase as the database, I had little experience dealing with servers and had no idea that fixing those issues would take this long. We managed to fix the CORS issue in about two days, but did not completely fix the mixed content issue.
    * Another difficulty was the discussion part. As there were more decision making to do in the model part, frequent discussion was very necessary but not done enough. Also, as I was working with two skilled AI engineers without much HCI background, leading the discussion more towards the user's perspective was not easy. I feel like face-to-face team meetings would have decreased the meeting time.
* List one useful skill you learned while working on the high-fi prototype.
    * I finally learned how to use React Hook! I have been waiting to learn it but had no chance, and liked it much more than the old react as I was able to write code more neatly and efficiently in the functional form. I also learned a lot about front-server connection.